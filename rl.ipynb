{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2356e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1f1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48a77c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0d1f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc29a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfa0687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3175699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torch import multiprocessing\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import nn\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import (Compose, DoubleToFloat, ObservationNorm, StepCounter,\n",
    "                          TransformedEnv)\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
    "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
    "from torchrl.objectives import ClipPPOLoss\n",
    "from torchrl.objectives.value import GAE\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30ac48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "num_cells = 256  # number of cells in each layer i.e. output dim.\n",
    "lr = 3e-4\n",
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd34c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_per_batch = 1000\n",
    "# For a complete training, bring the number of frames up to 1M\n",
    "total_frames = 50_000\n",
    "sub_batch_size = 64  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
    "num_epochs = 10  # optimization steps per batch of data collected\n",
    "clip_epsilon = (\n",
    "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
    ")\n",
    "gamma = 0.99\n",
    "lmbda = 0.95\n",
    "entropy_eps = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91081252",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_env = GymEnv(\"InvertedDoublePendulum-v4\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8048388",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "    base_env,\n",
    "    Compose(\n",
    "        # normalize observations\n",
    "        ObservationNorm(in_keys=[\"observation\"]),\n",
    "        DoubleToFloat(),\n",
    "        StepCounter(),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b35deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.transform[0].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37a4501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization constant shape: torch.Size([11])\n",
      "observation_spec: Composite(\n",
      "    observation: UnboundedContinuous(\n",
      "        shape=torch.Size([11]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([11]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([11]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
      "        device=cuda:0,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    step_count: BoundedDiscrete(\n",
      "        shape=torch.Size([1]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, contiguous=True)),\n",
      "        device=cuda:0,\n",
      "        dtype=torch.int64,\n",
      "        domain=discrete),\n",
      "    device=cuda:0,\n",
      "    shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuous(\n",
      "    shape=torch.Size([1]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
      "    device=cuda:0,\n",
      "    dtype=torch.float32,\n",
      "    domain=continuous)\n",
      "input_spec: Composite(\n",
      "    full_state_spec: Composite(\n",
      "        step_count: BoundedDiscrete(\n",
      "            shape=torch.Size([1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, contiguous=True)),\n",
      "            device=cuda:0,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        device=cuda:0,\n",
      "        shape=torch.Size([])),\n",
      "    full_action_spec: Composite(\n",
      "        action: BoundedContinuous(\n",
      "            shape=torch.Size([1]),\n",
      "            space=ContinuousBox(\n",
      "                low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
      "                high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
      "            device=cuda:0,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        device=cuda:0,\n",
      "        shape=torch.Size([])),\n",
      "    device=cuda:0,\n",
      "    shape=torch.Size([]))\n",
      "action_spec (as defined by input_spec): BoundedContinuous(\n",
      "    shape=torch.Size([1]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, contiguous=True)),\n",
      "    device=cuda:0,\n",
      "    dtype=torch.float32,\n",
      "    domain=continuous)\n"
     ]
    }
   ],
   "source": [
    "print(\"normalization constant shape:\", env.transform[0].loc.shape)\n",
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)\n",
    "print(\"input_spec:\", env.input_spec)\n",
    "print(\"action_spec (as defined by input_spec):\", env.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7097f534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 14:42:16,162 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d65b1616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout of three steps: TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        done: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                observation: Tensor(shape=torch.Size([3, 11]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                reward: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                step_count: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([3]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        observation: Tensor(shape=torch.Size([3, 11]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        step_count: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        truncated: Tensor(shape=torch.Size([3, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "Shape of the rollout TensorDict: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(3)\n",
    "print(\"rollout of three steps:\", rollout)\n",
    "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "801e6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = nn.Sequential(\n",
    "    nn.LazyLinear(num_cells, device=device),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(num_cells, device=device),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(num_cells, device=device),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(2 * env.action_spec.shape[-1], device=device),\n",
    "    NormalParamExtractor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4152a34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchrl.modules.tensordict_module.actors\n"
     ]
    }
   ],
   "source": [
    "from torchrl.modules import ProbabilisticActor\n",
    "print(ProbabilisticActor.__module__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9499eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "policy_module = TensorDictModule(\n",
    "    actor_net, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce268abb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SafeSequential.__init__() got an unexpected keyword argument 'inplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m policy_module = \u001b[43mProbabilisticActor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43min_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mloc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistribution_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTanhNormal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistribution_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhigh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43maction_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_log_prob\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we'll need the log-prob for the numerator of the importance weights\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\modules\\tensordict_module\\actors.py:388\u001b[39m, in \u001b[36mProbabilisticActor.__init__\u001b[39m\u001b[34m(self, module, in_keys, out_keys, spec, **kwargs)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out_keys) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, Composite):\n\u001b[32m    386\u001b[39m     spec = Composite({out_keys[\u001b[32m0\u001b[39m]: spec})\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSafeProbabilisticModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\modules\\tensordict_module\\probabilistic.py:321\u001b[39m, in \u001b[36mSafeProbabilisticTensorDictSequential.__init__\u001b[39m\u001b[34m(self, partial_tolerant, *modules)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    318\u001b[39m     *modules: Union[TensorDictModule, ProbabilisticTensorDictModule],\n\u001b[32m    319\u001b[39m     partial_tolerant: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    320\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial_tolerant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartial_tolerant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m     \u001b[38;5;28msuper\u001b[39m(ProbabilisticTensorDictSequential, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m(\n\u001b[32m    323\u001b[39m         *modules, partial_tolerant=partial_tolerant\n\u001b[32m    324\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensordict\\nn\\probabilistic.py:1024\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.__init__\u001b[39m\u001b[34m(self, partial_tolerant, return_composite, inplace, *modules)\u001b[39m\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_det_part\u001b[39m\u001b[33m\"\u001b[39m] = TensorDictSequential(*modules[:-\u001b[32m1\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial_tolerant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartial_tolerant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28mself\u001b[39m.return_composite = return_composite\n",
      "\u001b[31mTypeError\u001b[39m: SafeSequential.__init__() got an unexpected keyword argument 'inplace'"
     ]
    }
   ],
   "source": [
    "policy_module = ProbabilisticActor(\n",
    "    module=policy_module,\n",
    "    spec=env.action_spec,\n",
    "    in_keys=[\"loc\", \"scale\"],\n",
    "    distribution_class=TanhNormal,\n",
    "    distribution_kwargs={\n",
    "        \"low\": env.action_spec.space.low,\n",
    "        \"high\": env.action_spec.space.high,\n",
    "    },\n",
    "    return_log_prob=True,\n",
    "    # we'll need the log-prob for the numerator of the importance weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_net = nn.Sequential(\n",
    "    nn.LazyLinear(num_cells, device=device),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(num_cells, device=device),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(num_cells, device=device),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(1, device=device),\n",
    ")\n",
    "\n",
    "value_module = ValueOperator(\n",
    "    module=value_net,\n",
    "    in_keys=[\"observation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d79041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running policy: TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        loc: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        observation: Tensor(shape=torch.Size([11]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        scale: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        step_count: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n",
      "Running value: TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        observation: Tensor(shape=torch.Size([11]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        state_value: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "        step_count: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "        truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cuda:0,\n",
      "    is_shared=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Running policy:\", policy_module(env.reset()))\n",
    "print(\"Running value:\", value_module(env.reset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e850230",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy_module,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=total_frames,\n",
    "    split_trajs=False,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(max_size=frames_per_batch),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f589d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'log_prob_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m advantage_module = GAE(\n\u001b[32m      2\u001b[39m     gamma=gamma, lmbda=lmbda, value_network=value_module, average_gae=\u001b[38;5;28;01mTrue\u001b[39;00m, device=device,\n\u001b[32m      3\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m loss_module = \u001b[43mClipPPOLoss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_network\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_network\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclip_epsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mentropy_bonus\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mentropy_eps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mentropy_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mentropy_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# these keys match by default but we set this for completeness\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_critic_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msmooth_l1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m optim = torch.optim.Adam(loss_module.parameters(), lr)\n\u001b[32m     17\u001b[39m scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n\u001b[32m     18\u001b[39m     optim, total_frames // frames_per_batch, \u001b[32m0.0\u001b[39m\n\u001b[32m     19\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\objectives\\ppo.py:905\u001b[39m, in \u001b[36mClipPPOLoss.__init__\u001b[39m\u001b[34m(self, actor_network, critic_network, clip_epsilon, entropy_bonus, samples_mc_entropy, entropy_coef, critic_coef, loss_critic_type, normalize_advantage, normalize_advantage_exclude_dims, gamma, separate_losses, reduction, clip_value, **kwargs)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clip_value, \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m    903\u001b[39m     clip_value = clip_epsilon \u001b[38;5;28;01mif\u001b[39;00m clip_value \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m905\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mClipPPOLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactor_network\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_network\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mentropy_bonus\u001b[49m\u001b[43m=\u001b[49m\u001b[43mentropy_bonus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43msamples_mc_entropy\u001b[49m\u001b[43m=\u001b[49m\u001b[43msamples_mc_entropy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mentropy_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mentropy_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcritic_coef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcritic_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_critic_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_critic_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_advantage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize_advantage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_advantage_exclude_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize_advantage_exclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparate_losses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparate_losses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parameters():\n\u001b[32m    922\u001b[39m     device = p.device\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\objectives\\ppo.py:430\u001b[39m, in \u001b[36mPPOLoss.__init__\u001b[39m\u001b[34m(self, actor_network, critic_network, entropy_bonus, samples_mc_entropy, entropy_coef, critic_coef, loss_critic_type, normalize_advantage, normalize_advantage_exclude_dims, gamma, separate_losses, advantage_key, value_target_key, value_key, functional, actor, critic, reduction, clip_value, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    427\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mclip_value must be a float or a scalar tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclip_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    428\u001b[39m         )\n\u001b[32m    429\u001b[39m \u001b[38;5;28mself\u001b[39m.register_buffer(\u001b[33m\"\u001b[39m\u001b[33mclip_value\u001b[39m\u001b[33m\"\u001b[39m, clip_value)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m log_prob_keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactor_network\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob_keys\u001b[49m\n\u001b[32m    431\u001b[39m action_keys = \u001b[38;5;28mself\u001b[39m.actor_network.dist_sample_keys\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(log_prob_keys) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensordict\\nn\\common.py:1301\u001b[39m, in \u001b[36mTensorDictModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1297\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1300\u001b[39m     \u001b[38;5;66;03m# no fallback for private attributes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattr__\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m), name)\n\u001b[32m   1302\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1303\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has no attribute named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1304\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute 'log_prob_keys'"
     ]
    }
   ],
   "source": [
    "advantage_module = GAE(\n",
    "    gamma=gamma, lmbda=lmbda, value_network=value_module, average_gae=True, device=device,\n",
    ")\n",
    "\n",
    "loss_module = ClipPPOLoss(\n",
    "    actor_network=policy_module,\n",
    "    critic_network=value_module,\n",
    "    clip_epsilon=clip_epsilon,\n",
    "    entropy_bonus=bool(entropy_eps),\n",
    "    entropy_coef=entropy_eps,\n",
    "    # these keys match by default but we set this for completeness\n",
    "    critic_coef=1.0,\n",
    "    loss_critic_type=\"smooth_l1\",\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim, total_frames // frames_per_batch, 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b57a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'key \"action\" not found in TensorDict with keys [\\'collector\\', \\'done\\', \\'loc\\', \\'observation\\', \\'scale\\', \\'step_count\\', \\'terminated\\', \\'truncated\\']'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensordict\\_td.py:2708\u001b[39m, in \u001b[36mTensorDict._get_str\u001b[39m\u001b[34m(self, key, default, **kwargs)\u001b[39m\n\u001b[32m   2707\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2708\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tensordict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   2709\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'action'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_12076\\2327526365.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m eval_str = \u001b[33m\"\"\u001b[39m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# We iterate over the collector until it reaches the total number of frames it was\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# designed to collect:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, tensordict_data \u001b[38;5;28;01min\u001b[39;00m enumerate(collector):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# we now have a batch of data to work with. Let's learn something from it.\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;28;01min\u001b[39;00m range(num_epochs):\n\u001b[32m     10\u001b[39m         \u001b[38;5;66;03m# We'll need an \"advantage\" signal to make PPO work.\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\collectors\\collectors.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    263\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    264\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m self.iterator()\n\u001b[32m    265\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m Exception:\n\u001b[32m    266\u001b[39m             self.shutdown()\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\collectors\\collectors.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1077\u001b[39m                 stack.enter_context(torch.cuda.stream(stream))\n\u001b[32m   1078\u001b[39m \n\u001b[32m   1079\u001b[39m             \u001b[38;5;28;01mwhile\u001b[39;00m self._frames < self.total_frames:\n\u001b[32m   1080\u001b[39m                 self._iter += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m                 tensordict_out = self.rollout()\n\u001b[32m   1082\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m tensordict_out \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1083\u001b[39m                     \u001b[38;5;66;03m# if a replay buffer is passed, there is no tensordict_out\u001b[39;00m\n\u001b[32m   1084\u001b[39m                     \u001b[38;5;66;03m#  frames are updated within the rollout function\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m unpack_rref_and_invoke_function(self, *args, **kwargs):\n\u001b[32m    543\u001b[39m         \u001b[38;5;66;03m# windows does not know torch._C._distributed_rpc.PyRRef\u001b[39;00m\n\u001b[32m    544\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m _os_is_windows \u001b[38;5;28;01mand\u001b[39;00m isinstance(self, torch._C._distributed_rpc.PyRRef):\n\u001b[32m    545\u001b[39m             self = self.local_value()\n\u001b[32m--> \u001b[39m\u001b[32m546\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(self, *args, **kwargs)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_contextlib.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m     @functools.wraps(func)\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m decorate_context(*args, **kwargs):\n\u001b[32m    115\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\collectors\\collectors.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1240\u001b[39m                         \u001b[38;5;66;03m# env_input = self._shuttle.clear_device_()\u001b[39;00m\n\u001b[32m   1241\u001b[39m                         env_input = self._shuttle\n\u001b[32m   1242\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1243\u001b[39m                     env_input = self._shuttle\n\u001b[32m-> \u001b[39m\u001b[32m1244\u001b[39m                 env_output, env_next_output = self.env.step_and_maybe_reset(env_input)\n\u001b[32m   1245\u001b[39m \n\u001b[32m   1246\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m self._shuttle \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m env_output:\n\u001b[32m   1247\u001b[39m                     \u001b[38;5;66;03m# ad-hoc update shuttle\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\envs\\common.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   3436\u001b[39m                 is_shared=False)\n\u001b[32m   3437\u001b[39m         \"\"\"\n\u001b[32m   3438\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m tensordict.device != self.device:\n\u001b[32m   3439\u001b[39m             tensordict = tensordict.to(self.device)\n\u001b[32m-> \u001b[39m\u001b[32m3440\u001b[39m         tensordict = self.step(tensordict)\n\u001b[32m   3441\u001b[39m         \u001b[38;5;66;03m# done and truncated are in done_keys\u001b[39;00m\n\u001b[32m   3442\u001b[39m         \u001b[38;5;66;03m# We read if any key is done.\u001b[39;00m\n\u001b[32m   3443\u001b[39m         tensordict_ = self._step_mdp(tensordict)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\envs\\common.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   1981\u001b[39m             tensordict_batch_size = self.batch_size\n\u001b[32m   1982\u001b[39m \n\u001b[32m   1983\u001b[39m         next_preset = tensordict.get(\u001b[33m\"next\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1984\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1985\u001b[39m         next_tensordict = self._step(tensordict)\n\u001b[32m   1986\u001b[39m         next_tensordict = self._step_proc_data(next_tensordict)\n\u001b[32m   1987\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1988\u001b[39m             \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\envs\\transforms\\transforms.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m    922\u001b[39m         \u001b[38;5;66;03m# No need to clone here because inv does it already\u001b[39;00m\n\u001b[32m    923\u001b[39m         \u001b[38;5;66;03m# tensordict = tensordict.clone(False)\u001b[39;00m\n\u001b[32m    924\u001b[39m         next_preset = tensordict.get(\u001b[33m\"next\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    925\u001b[39m         tensordict_in = self.transform.inv(tensordict)\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         next_tensordict = self.base_env._step(tensordict_in)\n\u001b[32m    927\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    928\u001b[39m             \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[32m    929\u001b[39m             \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchrl\\envs\\gym_like.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(self.action_keys) == \u001b[32m1\u001b[39m:\n\u001b[32m    297\u001b[39m             \u001b[38;5;66;03m# Use brackets to get non-tensor data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m             action = tensordict[self.action_key]\n\u001b[32m    299\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    300\u001b[39m             action = tensordict.select(*self.action_keys).to_dict()\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._convert_actions_to_numpy:\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensordict\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    572\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m istuple \u001b[38;5;28;01mor\u001b[39;00m isinstance(index, str):\n\u001b[32m    573\u001b[39m             \u001b[38;5;66;03m# _unravel_key_to_tuple will return an empty tuple if the index isn't a NestedKey\u001b[39;00m\n\u001b[32m    574\u001b[39m             idx_unravel = _unravel_key_to_tuple(index)\n\u001b[32m    575\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m idx_unravel:\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m self._get_tuple_maybe_non_tensor(idx_unravel, NO_DEFAULT)\n\u001b[32m    577\u001b[39m \n\u001b[32m    578\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (istuple \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m index) \u001b[38;5;28;01mor\u001b[39;00m (\u001b[38;5;28;01mnot\u001b[39;00m istuple \u001b[38;5;28;01mand\u001b[39;00m index \u001b[38;5;28;01mis\u001b[39;00m Ellipsis):\n\u001b[32m    579\u001b[39m             \u001b[38;5;66;03m# empty tuple returns self\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensordict\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, default, **kwargs)\u001b[39m\n\u001b[32m   6514\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _get_tuple_maybe_non_tensor(self, key, default, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m6515\u001b[39m         result = self._get_tuple(key, default, **kwargs)\n\u001b[32m   6516\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _pass_through(result):\n\u001b[32m   6517\u001b[39m             \u001b[38;5;66;03m# Only lazy stacks of non tensors are actually tensordict instances\u001b[39;00m\n\u001b[32m   6518\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, TensorDictBase):\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensordict\\_td.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, default, **kwargs)\u001b[39m\n\u001b[32m   2712\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _get_tuple(self, key, default, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m2713\u001b[39m         first = self._get_str(key[\u001b[32m0\u001b[39m], default, **kwargs)\n\u001b[32m   2714\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(key) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mor\u001b[39;00m first \u001b[38;5;28;01mis\u001b[39;00m default:\n\u001b[32m   2715\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m first\n\u001b[32m   2716\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensordict\\_td.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, default, **kwargs)\u001b[39m\n\u001b[32m   2706\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _get_str(self, key, default, **kwargs):\n\u001b[32m   2707\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2708\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._tensordict[key]\n\u001b[32m   2709\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m KeyError:\n\u001b[32m-> \u001b[39m\u001b[32m2710\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._default_get(key, default)\n",
      "\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensordict\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, default)\u001b[39m\n\u001b[32m   6448\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m NO_DEFAULT:\n\u001b[32m   6449\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[32m   6450\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6451\u001b[39m             \u001b[38;5;66;03m# raise KeyError\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6452\u001b[39m             raise KeyError(\n\u001b[32m   6453\u001b[39m                 _KEY_ERROR.format(key, type(self).__name__, sorted(self.keys()))\n\u001b[32m   6454\u001b[39m             )\n",
      "\u001b[31mKeyError\u001b[39m: 'key \"action\" not found in TensorDict with keys [\\'collector\\', \\'done\\', \\'loc\\', \\'observation\\', \\'scale\\', \\'step_count\\', \\'terminated\\', \\'truncated\\']'"
     ]
    }
   ],
   "source": [
    "logs = defaultdict(list)\n",
    "pbar = tqdm(total=total_frames)\n",
    "eval_str = \"\"\n",
    "\n",
    "# We iterate over the collector until it reaches the total number of frames it was\n",
    "# designed to collect:\n",
    "for i, tensordict_data in enumerate(collector):\n",
    "    # we now have a batch of data to work with. Let's learn something from it.\n",
    "    for _ in range(num_epochs):\n",
    "        # We'll need an \"advantage\" signal to make PPO work.\n",
    "        # We re-compute it at each epoch as its value depends on the value\n",
    "        # network which is updated in the inner loop.\n",
    "        advantage_module(tensordict_data)\n",
    "        data_view = tensordict_data.reshape(-1)\n",
    "        replay_buffer.extend(data_view.cpu())\n",
    "        for _ in range(frames_per_batch // sub_batch_size):\n",
    "            subdata = replay_buffer.sample(sub_batch_size)\n",
    "            loss_vals = loss_module(subdata.to(device))\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            # Optimization: backward, grad clipping and optimization step\n",
    "            loss_value.backward()\n",
    "            # this is not strictly mandatory but it's good practice to keep\n",
    "            # your gradient norm bounded\n",
    "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
    "    pbar.update(tensordict_data.numel())\n",
    "    cum_reward_str = (\n",
    "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
    "    )\n",
    "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
    "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
    "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
    "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
    "    if i % 10 == 0:\n",
    "        # We evaluate the policy once every 10 batches of data.\n",
    "        # Evaluation is rather simple: execute the policy without exploration\n",
    "        # (take the expected value of the action distribution) for a given\n",
    "        # number of steps (1000, which is our ``env`` horizon).\n",
    "        # The ``rollout`` method of the ``env`` can take a policy as argument:\n",
    "        # it will then execute this policy at each step.\n",
    "        with set_exploration_type(ExplorationType.DETERMINISTIC), torch.no_grad():\n",
    "            # execute a rollout with the trained policy\n",
    "            eval_rollout = env.rollout(1000, policy_module)\n",
    "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
    "            logs[\"eval reward (sum)\"].append(\n",
    "                eval_rollout[\"next\", \"reward\"].sum().item()\n",
    "            )\n",
    "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
    "            eval_str = (\n",
    "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
    "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
    "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
    "            )\n",
    "            del eval_rollout\n",
    "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
    "\n",
    "    # We're also using a learning rate scheduler. Like the gradient clipping,\n",
    "    # this is a nice-to-have but nothing necessary for PPO to work.\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(logs[\"reward\"])\n",
    "plt.title(\"training rewards (average)\")\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(logs[\"step_count\"])\n",
    "plt.title(\"Max step count (training)\")\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(logs[\"eval reward (sum)\"])\n",
    "plt.title(\"Return (test)\")\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(logs[\"eval step_count\"])\n",
    "plt.title(\"Max step count (test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e7646c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os\n",
    "\n",
    "# Gym is an OpenAI toolkit for RL\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a9bfde",
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python integer 1024 out of bounds for uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOverflowError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     env = gym_super_mario_bros.make(\u001b[33m\"\u001b[39m\u001b[33mSuperMarioBros-1-1-v0\u001b[39m\u001b[33m\"\u001b[39m, new_step_api=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     env = \u001b[43mgym_super_mario_bros\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSuperMarioBros-1-1-v0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_api_compatibility\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Limit the action-space to\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#   0. walk right\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#   1. jump right\u001b[39;00m\n\u001b[32m     10\u001b[39m env = JoypadSpace(env, [[\u001b[33m\"\u001b[39m\u001b[33mright\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mright\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m]])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym\\envs\\registration.py:640\u001b[39m, in \u001b[36mmake\u001b[39m\u001b[34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[39m\n\u001b[32m    637\u001b[39m     render_mode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     env = \u001b[43menv_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    642\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    643\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e).find(\u001b[33m\"\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrender_mode\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m) >= \u001b[32m0\u001b[39m\n\u001b[32m    644\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m apply_human_rendering\n\u001b[32m    645\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gym_super_mario_bros\\smb_env.py:52\u001b[39m, in \u001b[36mSuperMarioBrosEnv.__init__\u001b[39m\u001b[34m(self, rom_mode, lost_levels, target)\u001b[39m\n\u001b[32m     50\u001b[39m rom = rom_path(lost_levels, rom_mode)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# initialize the super object with the ROM path\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSuperMarioBrosEnv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# set the target world, stage, and area variables\u001b[39;00m\n\u001b[32m     54\u001b[39m target = decode_target(target, lost_levels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nes_py\\nes_env.py:126\u001b[39m, in \u001b[36mNESEnv.__init__\u001b[39m\u001b[34m(self, rom_path)\u001b[39m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mROM has trainer. trainer is not supported.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# try to read the PRG ROM and raise a value error if it fails\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m _ = \u001b[43mrom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprg_rom\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# try to read the CHR ROM and raise a value error if it fails\u001b[39;00m\n\u001b[32m    128\u001b[39m _ = rom.chr_rom\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nes_py\\_rom.py:204\u001b[39m, in \u001b[36mROM.prg_rom\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the PRG ROM of the ROM file.\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw_data[\u001b[38;5;28mself\u001b[39m.prg_rom_start:\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprg_rom_stop\u001b[49m]\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mfailed to read PRG-ROM on ROM.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nes_py\\_rom.py:198\u001b[39m, in \u001b[36mROM.prg_rom_stop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprg_rom_stop\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    197\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The exclusive stopping index of the PRG ROM.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prg_rom_start + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprg_rom_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m10\u001b[39;49m\n",
      "\u001b[31mOverflowError\u001b[39m: Python integer 1024 out of bounds for uint8"
     ]
    }
   ],
   "source": [
    "# Initialize Super Mario environment (in v0.26 change render mode to 'human' to see results on the screen)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", new_step_api=True)\n",
    "else:\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", render_mode='rgb', apply_api_compatibility=True)\n",
    "\n",
    "# Limit the action-space to\n",
    "#   0. walk right\n",
    "#   1. jump right\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
